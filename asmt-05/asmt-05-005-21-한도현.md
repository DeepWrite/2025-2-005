---
title: 005-21 한도현 (과제-05)
layout: home
nav_order: 21
parent: 과제-05 (개인별) 개조식 요약문 작성
permalink: /asmt-05/005-21
---

# 과제-05 개조식 요약문 작성 005-21 한도현 

## 📘 1. The Responsibility Gap: Ascribing Responsibility for the Actions of Learning Automata 요약 – Andreas Matthias (2004)

### A. 서지 정보  
- **저자**: Arlie Russell Hochschild
- **제목**: *The Responsibility Gap: Ascribing Responsibility for the Actions of Learning Automata*  
- **학술지**: Ethics and Information Technology, Vol. 6 
- **출판년도**: 2004
- **주제 분야**: 인공지능 윤리, 책임귀속, 철학


### B. 쟁점 (Issue)  
AI 시스템은 스스로 학습하고 의사결정을 수행한다, 이때 결과에 대한 책임은 누구에게 귀속되는가?
→ 프로그램의 실행흐름(flow of excution)에 대한 통제력을 잃은 인간과 기계 사이에서 도덕적 책임은 어떻게 귀속될 수 있는가?


### C. 딜레마 (Dilemma)  
**양립 불가능한 두 설명 사이에서 발생하는 이론적 긴장**:

| 선택지 | 이론적 문제 |
|--------|-------------|
| 인간이 책임을 져야한다. | 인공지능의 통제력을 가지기 어렵다. |
| 기계가 책임을 져야한다. | 기계는 의도, 인식, 자유의지의 문제로 책임주체가 되기 어렵다. |

→ 이 딜레마 속에서 누구도 책임을 지기 어려운 상황인 '책임공백(Resposibility Gap)'이 발생한다.


### D. 옹호하려는 논제 (Thesis)  
> 인공지능은 인간의 기계에 대한 통제력을 약화시키며 기존 도덕적 개념으로 행위의 결과를 귀속할 수 없는 '책임공백(Responsibility gap)'을 만든다.

### E. 논증 전략 (Argument Strategy)  
- **추론 유형**: 사례 기반 귀납, 개념분석
- **논증의 구조**:
  기본구조
  - 전통적 도덕의 책임 개념은 통제를 전제한다.  
  - 학습형 기계(인공지능)은 프로그래머(인간)이 통제할 수 없다.    
  - 예시: 자율주행 탐사선이 스스로 낭떠러지에 떨어짐, 학습형 엘리베이터가 승객을 장기간 기다리게 함, AI 병리진단 시스템이 오진을 함.
  - 이러한 통제 불가능 사례에서 제작자, 프로그래머는 예측불가능성과 통제력 감소 때문에 완전한 책임 주체가 될 수 없다.
  - 따라서 책임공백(Responsibility gap)이 발생하고 이는 도덕 체계의 한계이다.


### F. 인용 가능한 핵심 구절
> “There is an increasing class of machine actions where traditional ways of responsibility ascription are not compatible with our sense of justice.” (p. 177)
> “Thus, we face an ever-widening responsibility gap, which, if not addressed properly, poses a threat to both the consistency of the moral framework of society and the
foundation of the liability concept in law." (p.176)


### G. 활용
- 자율주행차량, AI 병리진단 시스템 등 인간이 예측하기 어려운 시스템의 책임에 대한 새로운 도덕적 기준 필요성 부각가능
- '통제' 기반 책임에 대한 개념을 돌아보는 계기가 될 수 있음  


---

## 📘 2. Artificial intelligence and responsibility gaps: what is the problem? – Königs, P (2022)

- **서지정보**: Königs, P. Artificial intelligence and responsibility gaps: what is the problem?. Ethics Inf Technol 24, 36 (2022).

- **쟁점**: 인공지능의 등장으로 제기되는 '책임공백(Responsibility gap)'이 실재하며, 실재한다면 그것이 심각한 도덕적 문제인가?
- **딜레마**: 인공지능의 자율성과 예측불가능성은 책임공백의 우려를 낳는다. / 그러나 인간의 명백한 과실이나 악의가 개입된 경우 책임을 물을 수 있어 책임공백이 발생하지 않는다.
- **주장**: 책임공백(Responsibility gap)은 악의나 과실이 없는 상태에서만 발생하므로 발생이 명확하지 않고 과장되었다. 
- **논증 방식**: Königs, P는 책임공백을 주장하는 학자들에게 두가지 근거를 제시하며 반박하는 방식으로 책임공백이 과장되었음을 주장한다. 첫 번째는 '타당성 제약'으로 책임공백은 인간의 과실이나 악의가 없는 경우에만 발생할 수 있는 문제이기 때문에 Andreas Matthias가 제시한 책임공백은 더 구체적인 조건이 있어야 한다고 주장한다. 두 번째로는 책임공백이 존재하더라도 그 우려가 크지 않다고 주장한다. 책임공백이 존재하면 비난하는 것, 손해배상을 요구하는 것, 처벌하는 것이 부당하여 사람들이 주의를 기울여 행동하는 억제책이 부족해질 것이란 주장이 책임공백 존재론자들이 주장하는 것이다. 그러나 저자는 '타당성 제약'의 적용을 받기 때문에 책임공백이 발생하더라도 주의를 기울이지 않는 것 자체로 충분히 비난받을 만하다, 즉 인간이 책임을 지는 것이 상식적이라 책임공백은 우려할 필요없다 주장한다.

---

## 📘 3. There is a problem, but not a responsibility gap – Kasar, P (2025)

- **서지정보**: Kasar, P. There is a problem, but not a responsibility gap. Ethics Inf Technol 27, 47 (2025).

- **쟁점**: 인공지능 시스템이 유해한 결과를 초래했을 때, 전통적인 책임의 조건인 통제와 인식이 부족하여 누구에게도 책임을 물을 수 없는 책임공백(Responsibility gap)의 문제가 실제로 발생하는가? 
- **딜레마**: 인공지능의 자율적 행동으로 인간은 결과에 대한 통제력과 예측가능성이 없어 책임을 물을 수 없다. 그러나 아무도 책임을 질 수 없다면 정의의 원칙이 훼손된다.
- **주장**: 인공지능으로 인한 '책임공백' 문제는 '의도하지 않은 행동(Unintentional action)'에 대한 책임귀속문제로 재구성해야한다. 즉, 인공지능의 유해한 결과는 인간의 행위로 책임을 져야한다. 다만  '비난'은 면제되어도 '도덕적 잔여(moral residue)'에 따라 '회복적 의무(reparative obligations)'를 지니도록 책임이 수정된다.
- **논증 방식**: Kasar, P는 '책임공백'을 '의도하지 않은 행동'에 대한 책임귀속문제로 재구성한다. 인공지능은 과업자율성(task autonomy)는 있지만 목표자율성(goal autonomy)가 없어 타율적 존재임을 우선 논증한다. 그리고 다중 행위자 모델을 통해 인공지능이 인간의 의도적 행위임을 추적한다. 마지막으로 이에 따라 비난은 면제되더라도 사과나 보상의무가 남는다는 Paulina Sliwa의 '도덕적 잔여'개념을 활용하여 책임이 소멸하지 않음을, 즉 책임공백이 없음을 주장한다.


