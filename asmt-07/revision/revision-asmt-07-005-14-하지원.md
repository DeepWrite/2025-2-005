---
title: (개선) 과제-07 개인별 논증 구조 작성하기 005-14 하지원
layout: home
nav_order: 99
parent: 005-14 하지원 (과제-07)
permalink: /asmt-07/005-14/revision
---

# (개선) 과제-07 개인별 논증 구조 작성하기 005-14 하지원 

## 개선 사항 메모

초안에서는 전제2가 단순히 “데이터 접근성이 기술 발전의 필요조건이다”에 머물러 결론(“AI 학습이 정당하다”)과 사실상 내용이 중복되어 있었으나, 수정본에서는 이를 “공익 실현의 필수조건이라면 정당하다”는 조건적 규범 명제로 재구성하였다. 또한 초안이 기술 중심의 논증이었던 데 반해, 수정본은 의료·기후·교육 등 공익적 가치의 구체적 사례를 추가하여 논제의 “공익 증진” 측면을 드러내 보완했다. 예상반론–재반박 부분도 단순한 인과 비판에서 벗어나, “공익이 곧 정당성을 보장하는가”라는 규범적 층위의 논리 공격과 “필요성 기반 정당화”로 논의를 확장하였다.

## 제목: 인공지능(AI) 학습 과정에서 인간 창작물을 활용하는 행위의 정당성  

## 1. 쟁점과 딜레마

| 구분 | 내용 |
|:---|:---|
| 주제(Topic) | AI가 인간 창작물을 학습 데이터로 활용하는 행위의 정당성 |
| 도전하려는 쟁점 | 기술 발전을 위한 데이터 활용이 공정 이용인가, 아니면 저작권 침해인가 |
| 딜레마/난제 | AI 학습을 허용하면 창작자의 권리 침해, 금지하면 기술 발전이 정체 |
| 딜레마/난제 해소/해결 방법 | 기술 발전과 공익성을 위해 인간 창작물을 학습데이터로 활용해야 한다는 논증 |

① 주제(Topic): 기술 발전과 공익성을 위한 인공지능(AI)의 인간 창작물 학습 데이터 활용의 필요성
② 도전하는 학술적 쟁점:AI 학습은 공정 이용에 해당하는가, 저작권 침해인가?

- **창작자의 권리 보호와 기술 혁신 촉진 중 어느 가치가 우선되는가?**  
- **AI 시대에 저작권 제도는 인간 중심에서 기술 중심으로 재편되어야 하는가?**  
- **인간 창작물의 사용이 불가피하다면, 어떤 형태, 어떤 범위까지의 사용이 정당화될 수 있는가?**

③ 유발되는 딜레마 또는 난제

- 딜레마 구조
  - **(A)** AI 학습을 허용하면 수많은 예술가·작가·디자이너의 창작물이 무단으로 사용되어 권리가 침해된다.
  - **(B)** 반면 학습을 금지하면 AI 산업 발전이 정체되고, 사회 전체의 지식 생산·창의 혁신이 위축된다.

④ 딜레마 해소 (또는 난제 해결) 전략

- AI 학습은 기존 창작물에 대한 **참조(reference)**를 통해 이루어지며, 이는 창작물의 직접적 복제(copy)가 아닌 통계적 학습 과정이다. (Samuelson, 2023; OpenAI, 2024)
- 저작권 침해의 우려는 존재하지만, 데이터 출처 공개·보상 체계·거부권(opt-out) 등의 제도적 장치를 통해 충분히 통제 가능하다. (European Commission, 2024; Wu & Zittrain, 2023)
- 따라서 **AI 학습의 공익성과 기술 발전의 사회적 편익**이 **잠재적 저작권 침해 위험보다 크며**, 적절한 윤리·법적 프레임워크 내에서 인간 창작물을 학습 데이터로 활용하는 것은 정당화된다.

## 2. 논증구조

### 기본구조

- **논제:** 인공지능(AI)이 인간 창작물을 학습 데이터로 활용하는 것은 기술 발전과 사회적 공익 증진을 위해 정당하다.
  - **전제1:** AI 학습은 창작물을 직접 복제하거나 상업적으로 도용하는 것이 아니라, 다수의 데이터를 통해 창작 패턴을 일반화하는 과정이다.
    - AI의 학습은 개별 창작물의 형식과 표현을 그대로 복제하는 것이 아니라, 언어·음악·시각 표현의 통계적 규칙을 학습해 새로운 결과물을 생성한다.
   - 이러한 과정은 교육·연구 목적의 데이터 분석과 유사하며, 창작물의 변형적 활용으로서 '공정 이용(fair use)’ 범주로 해석될 수 있다(Samuelson, 2023, p.216).
  - **전제2:** 만약 AI 학습이 공익 실현에 필수적인 기술 발전을 가능하게 한다면, 그 학습은 공익 실현을 위한 정당한 행위로 간주된다.
    - AI 기술 발전은 단순한 산업 경쟁력 강화를 넘어, 사회 전반의 공익 실현(의료 진단, 기후 예측, 교육 접근성 향상 등)을 가능하게 한다. 따라서 이러한 기술 발전이 사회적으로 필수불가결한 조건이라면, 그 자체로 공익 실현의 정당화 근거가 된다.
    - 학습 데이터 접근이 과도하게 제한되면 모델의 표현 능력과 정확도가 급격히 하락하며, 공익을 위한 혁신 산업(의료 영상 분석, 언어 번역, 디자인 자동화 등) 전반의 발전이 정체된다(Wu & Zittrain, 2023, p.820).
  - **전제3:** 잠재적 저작권 침해 위험은 제도적 설계로 통제 가능하다.
      - AI 학습이 저작권 침해로 이어질 가능성은 존재하지만, 데이터 출처 공개(Transparency), 저작권자 거부권(opt-out), 보상 시스템(royalty sharing) 등의 제도적 장치를 통해 충분히 완화할 수 있다(European Commission, 2024).
      - 실제로 EU AI Act(2024)는 이러한 통제 메커니즘을 법제화함으로써 기술 발전과 권리 보호 간 균형 모델을 제시하였다.
- **결론:** 따라서, 인간 창작물을 학습데이터로 이용하지 않는다면 기술 발전이 근본적으로 제약된다. 즉, 적절한 법적·윤리적 통제 아래에서의 AI 학습은 기술 발전을 통한 공익 증진의 정당한 형태로 볼 수 있다.

### 예상반론과 재반박

- **예상반론(연역적 논증의 타당성 공격):** **전제2**에서 “만약 AI 학습이 공익 실현에 필수적인 기술 발전을 가능하게 한다면, 그 학습은 공익 실현을 위한 정당한 행위로 간주된다”는 주장은 결과적 공익을 정당성의 근거로 삼는 논리적 비약을 내포하고 있다.
  - 논리적 취약점 지적: 전제2는 ‘공익 실현의 가능성’과 ‘행위의 정당성’을 동일선상에 두고 있으나, 이 둘은 논리적으로 별개의 범주다. 어떤 행위가 공익을 가져올 수 있다고 해서 그것이 곧 정당하다고 단정할 수는 없다. 예컨대 개인정보 수집이나 감시 기술은 공공안전 향상이라는 공익적 결과를 낳을 수 있지만, 동시에 개인의 권리를 침해할 위험을 가진다. 이러한 경우 **“공익이 실현된다면 정당하다”**는 주장은 결과를 통해 수단을 정당화하는 도구주의적 오류를 범한다. 따라서 전제2는 “공익 실현이 가능하다는 것은 정당하다”는 규범적 조건문의 논리적 타당성이 충분히 입증되지 못한 채, 결과 중심적 판단의 위험을 지닌다.

- **재반박:** 전제2는 ‘공익을 가져오는 행위는 언제나 정당하다’는 결과론적 명제가 아니다. 오히려 “공익 실현을 위한 기술 발전이 필수적이고 불가피한 조건이라면, 그 행위는 정당하다”는 필요성에 기반한 조건적 정당화이다. 즉, 정당성의 근거를 단순히 공익의 결과에 두는 것이 아니라, 공익 실현을 위해 그 행위가 합리적이고 불가피한 수단인가에 둔다. 따라서 전제2는 공익 결과의 가치로 수단을 정당화하는 도구주의적 사고가 아니라, 공익 실현의 필요조건이 충족될 때 정당성이 필연적으로 귀결되는 연역적 규범 논리를 제시한다.
다시 말해, AI 학습이 공익 실현의 필수적인 기술 발전을 가능하게 한다면, 이는 단순히 유익한 결과를 낳는 행위가 아니라, 사회적·윤리적으로 요구되는 행위로 간주될 수 있다. 따라서 전제2를 결과 중심의 “낙수 효과” 논리로 해석해 부정하는 것은, 필요성에 기반한 조건 논리를 결과론적 명제로 오독하는 오류에 해당한다.

## 참고문헌

- Samuelson, P. (2023). Generative AI meets copyright. Science, 381(6654), 158-161.
- Samuelson, P. (2023). Legal Challenges to Generative AI, Part II. Communications of the ACM, 66(11)
- Zhong, H., Chang, J., Yang, Z., Mahawaga Arachchige, P., & Xue, M. (2023). Copyright Protection and Accountability of Generative AI: Attack, Watermarking and Attribution. arXiv Preprint.