---
title: 005-14 하지원 (과제-07)
layout: home
nav_order: 14
parent: 과제-07 개인별 논증 구조 작성하기
permalink: /asmt-07/005-14
---

# 과제-07 개인별 논증 구조 작성하기 005-14 하지원

## 제목: 인공지능(AI) 학습 과정에서 인간 창작물을 활용하는 행위의 정당성  

## 1. 쟁점과 딜레마

| 구분 | 내용 |
|:---|:---|
| 주제(Topic) | AI가 인간 창작물을 학습 데이터로 활용하는 행위의 정당성 |
| 도전하려는 쟁점 | 기술 발전을 위한 데이터 활용이 공정 이용인가, 아니면 저작권 침해인가 |
| 딜레마/난제 | AI 학습을 허용하면 창작자의 권리 침해, 금지하면 기술 발전이 정체 |
| 딜레마/난제 해소/해결 방법 | 기술 발전과 공익성을 위해 인간 창작물을 학습데이터로 활용해야 한다는 논증 |

① 주제(Topic): 기술 발전과 공익성을 위한 인공지능(AI)의 인간 창작물 학습 데이터 활용의 필요성
② 도전하는 학술적 쟁점:AI 학습은 공정 이용에 해당하는가, 저작권 침해인가?

- **창작자의 권리 보호와 기술 혁신 촉진 중 어느 가치가 우선되는가?**  
- **AI 시대에 저작권 제도는 인간 중심에서 기술 중심으로 재편되어야 하는가?**  
- **인간 창작물의 사용이 불가피하다면, 어떤 형태, 어떤 범위까지의 사용이 정당화될 수 있는가?**

③ 유발되는 딜레마 또는 난제

- 딜레마 구조
  - **(A)** AI 학습을 허용하면 수많은 예술가·작가·디자이너의 창작물이 무단으로 사용되어 권리가 침해된다.
  - **(B)** 반면 학습을 금지하면 AI 산업 발전이 정체되고, 사회 전체의 지식 생산·창의 혁신이 위축된다.

④ 딜레마 해소 (또는 난제 해결) 전략

- AI 학습은 기존 창작물에 대한 **참조(reference)**를 통해 이루어지며, 이는 창작물의 직접적 복제(copy)가 아닌 통계적 학습 과정이다. (Samuelson, 2023; OpenAI, 2024)
- 저작권 침해의 우려는 존재하지만, 데이터 출처 공개·보상 체계·거부권(opt-out) 등의 제도적 장치를 통해 충분히 통제 가능하다. (European Commission, 2024; Wu & Zittrain, 2023)
- 따라서 **AI 학습의 공익성과 기술 발전의 사회적 편익**이 **잠재적 저작권 침해 위험보다 크며**, 적절한 윤리·법적 프레임워크 내에서 인간 창작물을 학습 데이터로 활용하는 것은 정당화된다.

## 2. 논증구조

### 기본구조

- **논제:** 인공지능(AI)이 인간 창작물을 학습 데이터로 활용하는 것은 기술 발전과 사회적 공익 증진을 위해 정당하다.
  - **전제1:** AI 학습은 창작물을 직접 복제하거나 상업적으로 도용하는 것이 아니라, 다수의 데이터를 통해 창작 패턴을 일반화하는 과정이다.
    - AI의 학습은 개별 창작물의 형식과 표현을 그대로 복제하는 것이 아니라, 언어·음악·시각 표현의 통계적 규칙을 학습해 새로운 결과물을 생성한다.
	- 이러한 과정은 교육·연구 목적의 데이터 분석과 유사하며, 법적으로도 ‘공정 이용(fair use)’ 범주로 해석될 수 있다(Samuelson, 2023, p.216).
  - **전제2:** AI 기술 발전은 충분하고 다양한 학습 데이터 접근성이 보장될 때만 가능하다.
    - AI의 성능은 데이터의 양(quantity), 질(quality), **다양성(diversity)**에 비례한다.
    - 학습 데이터 접근이 과도하게 제한되면 모델의 표현 능력과 정확도가 급격히 하락하며, 혁신 산업(의료 영상 분석, 언어 번역, 디자인 자동화 등) 전반의 발전이 정체된다(Wu & Zittrain, 2023, p.820).
  - **전제3:** 잠재적 저작권 침해 위험은 제도적 설계로 통제 가능하다.
      - AI 학습이 저작권 침해로 이어질 가능성은 존재하지만, 데이터 출처 공개(Transparency), 저작권자 거부권(opt-out), 보상 시스템(royalty sharing) 등의 제도적 장치를 통해 충분히 완화할 수 있다(European Commission, 2024).
      - 실제로 EU AI Act(2024)는 이러한 통제 메커니즘을 법제화함으로써 기술 발전과 권리 보호 간 균형 모델을 제시하였다.
- **결론:** 따라서, 인간 창작물을 학습데이터로 이용하지 않는다면 기술 발전이 근본적으로 제약된다. 

### 예상반론과 재반박

- **예상반론(연역적 논증의 타당성 공격):** **전제3**에서 “저작권 침해 위험은 제도적 설계로 통제 가능하다”는 주장은 경험적 타당성이 부족하다.
  - 논리적 취약점 지적: 연역적 논증에서 “통제 가능하다”는 명제는 실제 사례에서 반복적으로 검증된 실효성이 입증되어야 한다. 그러나 아직 EU AI Act(2024)는 시행 초기 단계이며, 데이터 출처 공개나 opt-out 제도가 실제 침해 방지로 이어진다는 실증적 근거는 부족하다. 따라서 이 전제는 ‘가능성(possibility)’을 ‘현실적 타당성(validity)’으로 과도하게 확장한 오류를 범하고 있다.

- **재반박:** 전제3은 “현재 제도가 완벽하다”가 아니라 “제도 설계를 통해 통제가 가능하다”는 논리적 가능성의 주장으로 읽혀야 한다. 실제로 과거의 저작권 기술(예: 디지털 워터마킹, DRM, 저작물 식별 알고리즘) 사례에서 보듯, 법·기술·윤리 제도가 결합될 경우 데이터 이용의 투명성과 권리 보호가 실질적으로 향상되어 왔다.
EU AI Act는 이러한 국제적 추세의 제도적 발전 방향을 제시한 것이며, **통제의 가능성이 입증되지 않았다는 이유로 정당성을 부정하는 것은 논리적 오류(ignoratio elenchi)**에 해당한다. 즉, ‘완전한 통제 불가능’이 입증되지 않는 한, 제도적 설계에 의한 위험 완화 가능성은 충분히 정당한 전제로 유지된다.

## 참고문헌

- Samuelson, P. (2023). Generative AI meets copyright. Science, 381(6654), 158-161.
- Samuelson, P. (2023). Legal Challenges to Generative AI, Part II. Communications of the ACM, 66(11)
- Zhong, H., Chang, J., Yang, Z., Mahawaga Arachchige, P., & Xue, M. (2023). Copyright Protection and Accountability of Generative AI: Attack, Watermarking and Attribution. arXiv Preprint.